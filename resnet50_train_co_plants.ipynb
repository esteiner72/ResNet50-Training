{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook trains a ResNet50 convolutional neural network for image classification. It is trained using an A100 GPU on a custom dataset containing Colorado plants created using the iNaturalist API. The dataset contains:\n",
        "\n",
        "- 434 classes (plant species)\n",
        "- 180710 features (images)\n",
        "- Between 400 and 600 features per class\n",
        "\n",
        "Final performance metrics on validation dataset for model after initial training and two stages of gradual fine tuning:\n",
        "\n",
        "- val_accuracy: 0.9223 (92.2%)\n",
        "- val_loss: 0.3364\n",
        "\n",
        "Model implemented in academic capstone team project \"LeafQuest\"\n"
      ],
      "metadata": {
        "id": "0rG8osmUUHTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial Training & Setup"
      ],
      "metadata": {
        "id": "c_FVGG9LbnR7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv_SItTJmDyD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "TFRECORD_FILENAME = \"drive/MyDrive/resnet50_dataset.tfrecord\"\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 434\n",
        "EPOCHS_INITIAL = 15\n",
        "EPOCHS_FINE = 5\n",
        "TOTAL_EXAMPLES = 180710"
      ],
      "metadata": {
        "id": "38hrwMQLmLOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to provide additional pre-processing, specific to ResNet50's input\n",
        "def parse_example(example_proto):\n",
        "    feature_description = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
        "    image = tf.io.decode_jpeg(parsed['image'], channels=3)\n",
        "    image = tf.image.resize(image, IMAGE_SIZE)\n",
        "\n",
        "    image = tf.keras.applications.resnet.preprocess_input(tf.cast(image, tf.float32))\n",
        "    label = parsed['label']\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "G08TAsOAmU9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/validation split of dataset with shuffling\n",
        "def get_finite_dataset():\n",
        "    raw_dataset = tf.data.TFRecordDataset(TFRECORD_FILENAME)\n",
        "    dataset = raw_dataset.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# We use a buffer size of 50000 to have a good enough sample size of the total examples to shuffle while also limiting RAM usage\n",
        "# Using TOTAL_EXAMPLES would be a perfect shuffle, but it would require too much ram for this environment\n",
        "dataset = get_finite_dataset().shuffle(buffer_size=50000)\n",
        "# Using a\n",
        "train_size = int(0.8 * TOTAL_EXAMPLES)\n",
        "\n",
        "train_ds = dataset.take(train_size).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = dataset.skip(train_size).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "zZAMcBwQvryQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up base moidel\n",
        "base_model = tf.keras.applications.ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
        ")\n",
        "\n",
        "# Freeze base so it doesn't get overwritten\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "IKWy8Fc9mZfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial training\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS_INITIAL,\n",
        "    validation_data=val_ds,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChzmxFrymd3X",
        "outputId": "971d29fb-0933-4ec1-db5d-db0661c2793a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "   2259/Unknown \u001b[1m112s\u001b[0m 35ms/step - accuracy: 0.3210 - loss: 3.1827"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 72ms/step - accuracy: 0.3210 - loss: 3.1826 - val_accuracy: 0.4937 - val_loss: 2.1994\n",
            "Epoch 2/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.5149 - loss: 2.0533 - val_accuracy: 0.5599 - val_loss: 1.8465\n",
            "Epoch 3/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.5665 - loss: 1.7849 - val_accuracy: 0.5943 - val_loss: 1.6752\n",
            "Epoch 4/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.5962 - loss: 1.6497 - val_accuracy: 0.6233 - val_loss: 1.5320\n",
            "Epoch 5/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6185 - loss: 1.5398 - val_accuracy: 0.6443 - val_loss: 1.4411\n",
            "Epoch 6/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 65ms/step - accuracy: 0.6332 - loss: 1.4639 - val_accuracy: 0.6607 - val_loss: 1.3535\n",
            "Epoch 7/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 65ms/step - accuracy: 0.6450 - loss: 1.4131 - val_accuracy: 0.6708 - val_loss: 1.3091\n",
            "Epoch 8/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6520 - loss: 1.3792 - val_accuracy: 0.6902 - val_loss: 1.2258\n",
            "Epoch 9/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6584 - loss: 1.3385 - val_accuracy: 0.6981 - val_loss: 1.1799\n",
            "Epoch 10/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6680 - loss: 1.3025 - val_accuracy: 0.6973 - val_loss: 1.1680\n",
            "Epoch 11/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6729 - loss: 1.2798 - val_accuracy: 0.7126 - val_loss: 1.1270\n",
            "Epoch 12/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 65ms/step - accuracy: 0.6792 - loss: 1.2499 - val_accuracy: 0.7144 - val_loss: 1.1094\n",
            "Epoch 13/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6816 - loss: 1.2370 - val_accuracy: 0.7287 - val_loss: 1.0468\n",
            "Epoch 14/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 65ms/step - accuracy: 0.6847 - loss: 1.2148 - val_accuracy: 0.7313 - val_loss: 1.0290\n",
            "Epoch 15/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6879 - loss: 1.2144 - val_accuracy: 0.7384 - val_loss: 1.0004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "gyjvDWmoCAMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 1 Fine-Tuning\n",
        "Unfreezing final 20 layers of ResNet50 to gradually train the model to classify more advanced features. Using a low learning rate combined with \"ReduceLROnPlateau\" callback to ensure the model converges more effectively if validation loss plateaus and isn't improving."
      ],
      "metadata": {
        "id": "11YjSJxqbj7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradual unfreezing using ReduceLROnPlateau scheduler in case of plateau\n",
        "# Starting with last 20 layers\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-20:]:\n",
        "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        layer.trainable = False\n",
        "    else:\n",
        "        layer.trainable = True\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)"
      ],
      "metadata": {
        "id": "htC2E1commNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_fine_stage1 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[lr_scheduler]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifJfEVi2B_O1",
        "outputId": "fd19b766-8e19-4363-fb00-74d538d1c8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 75ms/step - accuracy: 0.6625 - loss: 1.3115 - val_accuracy: 0.8069 - val_loss: 0.7871 - learning_rate: 1.0000e-05\n",
            "Epoch 2/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 69ms/step - accuracy: 0.7384 - loss: 0.9913 - val_accuracy: 0.8299 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
            "Epoch 3/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.7710 - loss: 0.8538 - val_accuracy: 0.8439 - val_loss: 0.6476 - learning_rate: 1.0000e-05\n",
            "Epoch 4/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 69ms/step - accuracy: 0.7934 - loss: 0.7601 - val_accuracy: 0.8572 - val_loss: 0.5819 - learning_rate: 1.0000e-05\n",
            "Epoch 5/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 69ms/step - accuracy: 0.8157 - loss: 0.6750 - val_accuracy: 0.8689 - val_loss: 0.5438 - learning_rate: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 2 Fine-Tuning\n",
        "Unfreezing final 40 layers of ResNet50 to achieve the same goal as stage 1."
      ],
      "metadata": {
        "id": "BZ345UEmb7M8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tuning for last 40 layers\n",
        "for layer in base_model.layers[:-40]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-40:]:\n",
        "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        layer.trainable = False\n",
        "    else:\n",
        "        layer.trainable = True"
      ],
      "metadata": {
        "id": "BMzhaH5fHDQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_fine_stage2 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[lr_scheduler]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sjWsyvZHFrQ",
        "outputId": "1108cf29-4b29-4bc1-e2cd-df2e051f8af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "   2259/Unknown \u001b[1m99s\u001b[0m 36ms/step - accuracy: 0.8339 - loss: 0.6041"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 69ms/step - accuracy: 0.8339 - loss: 0.6041 - val_accuracy: 0.8798 - val_loss: 0.5007 - learning_rate: 1.0000e-05\n",
            "Epoch 2/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.8532 - loss: 0.5352 - val_accuracy: 0.8933 - val_loss: 0.4488 - learning_rate: 1.0000e-05\n",
            "Epoch 3/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.8654 - loss: 0.4833 - val_accuracy: 0.9019 - val_loss: 0.4084 - learning_rate: 1.0000e-05\n",
            "Epoch 4/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.8800 - loss: 0.4311 - val_accuracy: 0.9107 - val_loss: 0.3792 - learning_rate: 1.0000e-05\n",
            "Epoch 5/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.8925 - loss: 0.3861 - val_accuracy: 0.9223 - val_loss: 0.3364 - learning_rate: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"stage2_resnet50.keras\")"
      ],
      "metadata": {
        "id": "A9OnXDBGHH-q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
